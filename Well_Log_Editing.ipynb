{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)   #to display all the column information\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the separate log files fo each wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeCsv(file_directory,depth_col_name,*file):\n",
    "    file_path = os.path.join(file_directory,file[0])\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    for i in range(1,len(file)):\n",
    "        file_path = os.path.join(file_directory,file[i])\n",
    "        df = pd.read_csv(file_path)\n",
    "        data = pd.merge(data, df, on = depth_col_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = \"Boggess_AnisoMechPro.csv\"\n",
    "file_name2 = \"Boggess_PetroInterp.csv\"\n",
    "# file_directory = r\"C:\\Users\\tmo0005\\Desktop\\Thesis work\\Thesis work\\Well_Data_CSV\"\n",
    "file_directory = r\"../Thesis work/Thesis work/Well_Data_CSV\" \n",
    "depth_col_name = \"TDEP\"\n",
    "\n",
    "data_boggess =  MergeCsv(file_directory,depth_col_name, file_name1, file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = \"MIP_3H_IsoMechPro.csv\"\n",
    "file_name2 = \"MIP_3H_PetroInterp.csv\"\n",
    "# file_directory = r\"C:\\Users\\tmo0005\\Desktop\\Thesis work\\Thesis work\\Well_Data_CSV\"\n",
    "file_directory = r\"../Thesis work/Thesis work/Well_Data_CSV\" \n",
    "depth_col_name = \"DEPT\"\n",
    "\n",
    "data_mip3h =  MergeCsv(file_directory,depth_col_name, file_name1, file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = \"Whipkey_Main.csv\"\n",
    "file_name2 = \"Whipkey_Sonic.csv\"\n",
    "# file_directory = r\"C:\\Users\\tmo0005\\Desktop\\Thesis work\\Thesis work\\Well_Data_CSV\"\n",
    "file_directory = r\"../Thesis work/Thesis work/Well_Data_CSV\" \n",
    "depth_col_name = \"DEPT\"\n",
    "\n",
    "data_whipkey =  MergeCsv(file_directory,depth_col_name, file_name1, file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name1 = \"Poseidon_AnisoMechPro.csv\"\n",
    "file_name2 = \"Poseidon_PetroInterp.csv\"\n",
    "# file_directory = r\"C:\\Users\\tmo0005\\Desktop\\Thesis work\\Thesis work\\Well_Data_CSV\"\n",
    "file_directory = r\"../Thesis work/Thesis work/Well_Data_CSV\" \n",
    "depth_col_name = \"TDEP\"\n",
    "\n",
    "data_poseidon =  MergeCsv(file_directory,depth_col_name, file_name1, file_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the brittleness for each wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM_brit = (data_poseidon['YME_DYN']-data_poseidon['YME_DYN'].min())/(data_poseidon['YME_DYN'].max()-data_poseidon['YME_DYN'].min())\n",
    "PR_brit = (data_poseidon['PR_DYN']-data_poseidon['PR_DYN'].min())/(data_poseidon['PR_DYN'].max()-data_poseidon['PR_DYN'].min())\n",
    "\n",
    "df =  1/ data_poseidon['PR_DYN']\n",
    "PR_brit_inv = (df - df.min())/(df.max() - df.min())\n",
    "\n",
    "data_poseidon['Brittleness'] = (YM_brit + PR_brit) / 2\n",
    "data_poseidon['Brittleness_new'] = (YM_brit + (PR_brit_inv)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM_brit = (data_boggess['YME_DYN']-data_boggess['YME_DYN'].min())/(data_boggess['YME_DYN'].max()-data_boggess['YME_DYN'].min())\n",
    "PR_brit = (data_boggess['PR_DYN']-data_boggess['PR_DYN'].min())/(data_boggess['PR_DYN'].max()-data_boggess['PR_DYN'].min())\n",
    "\n",
    "df =  1/ data_boggess['PR_DYN']\n",
    "PR_brit_inv = (df - df.min())/(df.max() - df.min())\n",
    "\n",
    "data_boggess['Brittleness'] = (YM_brit + PR_brit) / 2\n",
    "data_boggess['Brittleness_new'] = (YM_brit + (PR_brit_inv)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM_brit = (data_mip3h['YME_DYN']-data_mip3h['YME_DYN'].min())/(data_mip3h['YME_DYN'].max()-data_mip3h['YME_DYN'].min())\n",
    "PR_brit = (data_mip3h['PR']-data_mip3h['PR'].min())/(data_mip3h['PR'].max()-data_mip3h['PR'].min())\n",
    "\n",
    "df =  1/ data_mip3h['PR']\n",
    "PR_brit_inv = (df - df.min())/(df.max() - df.min())\n",
    "\n",
    "data_mip3h['Brittleness'] = (YM_brit + PR_brit) / 2\n",
    "data_mip3h['Brittleness_new'] = (YM_brit + (PR_brit_inv)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate elastic property for whipkey\n",
    "Vp = 116.08 / data_whipkey['DT']\n",
    "Vs = 116.08 / data_whipkey['DTSM_FAST']\n",
    "Rhob = data_whipkey['RHOB']\n",
    "\n",
    "v = (Vp**2 - 2*Vs**2) / (2*(Vp**2 - Vs**2))\n",
    "E = (Rhob * Vs**2 * (3*Vp**2 - 4*Vs**2)) / (Vp**2 - Vs**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM_brit = (E-E.min())/(E.max()-E.min())\n",
    "PR_brit = (v-v.min())/(v.max()-v.min())\n",
    "\n",
    "df =  1/ v\n",
    "PR_brit_inv = (df - df.min())/(df.max() - df.min())\n",
    "\n",
    "data_whipkey['Brittleness'] = (YM_brit + PR_brit) / 2\n",
    "data_whipkey['Brittleness_new'] = (YM_brit + (PR_brit_inv)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the column names to the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poseidon.rename(columns = {\"TDEP\":\"DEPT\", \"NPHI_x\":\"NPHI\", \"RHOZ_x\":\"RHOZ\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boggess.rename(columns = {\"TDEP\":\"DEPT\", \"RHOZ_x\":\"RHOZ\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mip3h.rename(columns = {\"GR_x\":\"GR\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whipkey.rename(columns = {\"DT\":\"DTCO\", \"GR_x\":\"GR\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###creates a folder to save the csv files\n",
    "###checks if a folder called Well_Data_CSV already exists to avoid error\n",
    "new_file_directory = os.path.join(os.path.split(file_directory)[0], \"Well_Data_CSV_Merged\")\n",
    "if os.path.exists(new_file_directory):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(os.path.join(os.path.split(new_file_directory)[0],\"Well_Data_CSV_Merged\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_poseidon.to_csv(os.path.join(new_file_directory,\"Poseidon.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boggess.to_csv(os.path.join(new_file_directory,\"Boggess.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mip3h.to_csv(os.path.join(new_file_directory,\"Mip3h.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_whipkey.to_csv(os.path.join(new_file_directory,\"Whipkey.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
